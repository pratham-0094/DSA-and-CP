// asymptotic notation are used to compute the time and space complexities of algorithm

// 1 < logn < n < nlogn < n^2 < n^3 < ..... < 2^n < 3^n < ..... < n^n
//    ----------------------------------       ------------------------
//                 ^                                       ^
//                 |                                       |
//        polynomial complexities               exponent complexities

// if we get a time complexity formula in some form which cannot be simplified in terms of n directly, we cannot give the time complexity
// when we compute complexity we not get exact formula, we have to get a approximate formula
// the result of function in the form of polynomial is that a lower/higher value, is not exact

// omega - lower value - lower bound
// theta - exact value - tight bound
// bigh-oh - greater value - upper bound

// this can be used in the situation where we not get the exact polynomial
// when we are talking about expenses we take at most it must, at most therefore most of the time we prefer big-oh (upper bound)